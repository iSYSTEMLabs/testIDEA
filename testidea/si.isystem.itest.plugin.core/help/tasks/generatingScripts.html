<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<title>Generating scripts for test execution</title>
</head>

<body>
	<h1>Generating scripts for test execution</h1>

    This section describes creation of Python scripts for test execution.
    
	<h2>Preparation: Creating and editing test specifications</h2>

    The first step when implementing tests for our application is
    creation of test specifications. <i>testIDEA</i>
    is the tool to be used for this task. Add as many test
    specifications as you like, and run and test them
    with <i>testIDEA</i>. Once test specifications are ready, save them to
    file. The GUI part is done.
    
    
    <h2>Generating scripts</h2>

    To write a script, which will perform the required task, we have
    two possibilities. Either we use the script generator built into
    testIDEA, or write the script manually from scratch. Description
    of both procedures is following.

    <h3>Generating scripts from testIDEA</h3>

    This is the preferred option, especially if you are not familiar
    with <i>isystem.connect</i> API. The generated script is simple,
    yet it is designed to be easily configurable. Even if it does not
    contain all the required functionality, it is a good starting
    point for writing own scripts.
    <p>

    The script can be generated by selecting command
    <code>iTools | Generate Test Script</code> in <i>testIDEA</i>. The
    dialog shown below opens:
        
    <p align="center">
      <img width="90%" src="images/generateScriptDialog.png" />
    </p>

    The default settings give us good results, but there are also many
    possibilities for customization. Each control in a dialog has
    descriptive tool-tip, which describes the meaning of setting.
    <p/>
        
    <b>Tip:</b> Make sure that the names of <i>Imported modules</i> in
    testIDEA <code>File | Properties | Scripts</code> match
    existing modules with extension functions. If no extension
    functions are used by your test cases, then you can clear this
    field. Otherwise the generated script will fail
    with <i>ImportError</i> exception.        
    <p/>
    
    If the generated script does not meet our requirements, we can modify
    it and use it as a template. The only constraint for template are two
    lines with special comments used as markers of configuration section.
    These two lines should start with '
    <code>#@</code>
    ' special comment. Everything between these two lines is replaced with
    variables from the script generator dialog shown above. Everything
    else is copied from the template to the generated script.<br> If
    lines with special comment are not present in the template, the script
    is still generated, but <i>testIDEA</i> issues a warning. The
    generated script is equal to the given template in this case.
    	
    <h3>Writing scripts manually</h3>

    This section was more useful before the script generator was added to
    <i>testIDEA</i>, but the main concepts are still useful when we have
    special requirements and have to write the script from
    scratch.<p>
    

    Most of
    functionality shown in this section is implemented in class
    <code>isystem.itest.PTestCase</code> for Python and in
    class <i>CTestCase</i> for other languages.
    (see API documentation bundled with SDK). Before writing own
    code it is recommended to see documentation of this class and write own
    functions only if the provided class does not meet our requirements.
    <p>

    The main class for loading test specifications from <i>iyaml</i> file is
    <code>CTestBench</code>. Let's see an example:
    <pre>
      <b>import</b> isystem.connect <b>as</b> ic

      testBench = ic.CTestBench.load('myTests.iyaml', 0)
    </pre>

    That's it! Object
    <code>testBench</code>
    now contains everything we've created and saved in testIDEA. If we take
    a look at
    <a href="https://www.isystem.com/downloads/winIDEA/SDK/iSYSTEM.Python.SDK/documentation/isystem-connect-api/classisys_1_1_c_test_bench.html">
    CTestBench API</a>, we can see that it has methods for getting references
    to the three parts of information managed by testIDEA -
    <i>test environment</i>,
    <i>test specification</i>, and
    <i>test report configuration</i>. Each of these objects then provides
    additional methods to access test data. Classes
    <i>CTestEnvironmentConfig</i> and
    <i>CTestReportConfig</i> are usually not that interesting in scripting
    environment, since we usually already know settings like the output
    report format or initialization steps. The most important class is
    therefore
    <i>CTestSpecification</i>, which contains all information about tests
    and expected results.
    <i>isystem.test</i> API provides access to all test data, but usually
    we just want to execute the test. This can be done with the following
    code:

    <pre>
    rootTestSpec = testBench.getTestSpecification()
    rootTestSpec.setRunFlag(False)

    <b>import</b> isystem.itest <b>as</b> it
    testCase = it.PTestCase(connectionMgr)
    testCase.runTests(rootTestSpec, <b>None</b>, <b>None</b>)
    </pre>

	These lines will execute all the tests from file created with testIDEA.
	The
	<code>rootTestSpec</code>
	is only a container for all other test specifications, and contains no
	data for testing. That is also the reason to set its run flag to
	<code>false</code>
	. Otherwise we'll get the following runtime error:

	<pre>
      ValueError: Function name must not be empty string!
    </pre>


	If we want to get more control over test execution, we can execute base
	tests one by one. Example:

	<pre>
    <b>for</b> i <b>in</b> range(rootTestSpec.getNoOfDerivedSpecs()):
        testSpec = rootTestSpec.getDerivedTestSpec(i)
        testCase.runTests(testSpec, <b>None</b>)
    </pre>

	The next code snippet demonstrates filtering. It executes base tests
	which contain tag '
	<code>extended</code>
	':

	<pre>
    for i in range(rootTestSpec.getNoOfDerivedSpecs()):
        testSpec = rootTestSpec.getDerivedTestSpec(i)
        tags = ic.StrVector()
        testSpec.getTags(tags)

        if 'extended' in tags:
            testCase.runDerivedTests(testSpec, <b>None</b>, <b>None</b>)
    </pre>

	If we want to control execution of each tests, including derived tests,
	then recursion is useful, so we need to write the following function:

	<pre>
    <b>def</b> runDerivedTests(testCase, testSpec, filterTag, results):
        <i>"""
        This method runs derived tests recursively. Some basic filtering
        is performed on tags.
        """</i>

        <b>if</b> testSpec.getRunFlag():

            mergedTestSpec = testSpec.merge()

            tags = ic.StrVector()
            mergedTestSpec.getTags(tags)

            <b>if</b> filterTag in tags:
                <i># merge base test spec and the derived one into one test spec</i>

                <b>print</b> 'executing:', mergedTestSpec.getTestId()
                testCase.itest(mergedTestSpec, <b>None</b>)
                results.append(testCase.getTestResults()[0])

        numDerivedTestSpecs = testSpec.getNoOfDerivedSpecs()
        <b>for</b> idx <b>in</b> range(0, numDerivedTestSpecs):
            runDerivedTests(testCase, testSpec.getDerivedTestSpec(idx), filterTag, results)
    </pre>

	To execute tests we can write:

	<pre>
    rootTestSpec = testBench.getTestSpecification()
    rootTestSpec.setRunFlag(False)

    testResults = []
    runDerivedTests(testCase, rootTestSpec, 'extended', testResults)
    </pre>


	<h3>Reports</h3>

	After test execution we want to get report, either visual or stored to
	file. The code which produces basic output is shown below:

	<pre>
    <b>for</b> testResult in testResults:
        <b>if</b> testResult.isError():
            print "Error: ", testResult.getTestId()
        <b>else:</b>
            print "OK: ", testResult.getTestId()
    </pre>

	Saving to file is shown in examples mentioned below.
	<p />

	<h3>Script methods and monitor</h3>

	When we were calling the method
	<code>runTests()</code>
	in examples above, we've also specified the two additional parameters
	as
	<code>None</code>
	. The first parameter can be used to specify object with script methods
	specified in test specifications, and the second one may provide us
	feedback during execution. Implementation and usage of these two
	objects is shown in SDK examples
	<code>samples/itest/cumulativeCoverage.py</code>
	, and
	<code>samples/itest/scriptCallbackMethods.py</code>
	. See also SDK API documentation.

	<h3>Examples</h3>
	All the code shown above can be found in
	<i>iSYSTEM Python SDK</i>, files
	<code>samples/itest/loadRunReport.py</code>
	and
	<code>samples/itest/filterTests.py</code>
	. API for test reports is used in
	<code>samples/itest/testResults.py</code>
	.
	<p />
	SDK also contains other examples for advanced usage of
	<i>isystem.connect</i> and
	<i>isystem.test</i>. Script generated by
	<i>testIDEA</i> are also a good starting point.

    <br><br>&nbsp;
</body>
</html>
